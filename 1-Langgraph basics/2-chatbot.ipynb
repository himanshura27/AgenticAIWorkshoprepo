{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64ec3569",
   "metadata": {},
   "source": [
    "### Implementing simple chatbot using langgraph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a5fbf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph ,START , END\n",
    "\n",
    "## Reducer\n",
    "from typing import Annotated\n",
    "from langgraph.graph.message import add_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfdae9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages:Annotated[list,add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45474704",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31abfb95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-groq in c:\\agenticaiworkshop\\venv\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: groq<1.0.0,>=0.30.0 in c:\\agenticaiworkshop\\venv\\lib\\site-packages (from langchain-groq) (0.33.0)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in c:\\agenticaiworkshop\\venv\\lib\\site-packages (from langchain-groq) (1.0.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\agenticaiworkshop\\venv\\lib\\site-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\agenticaiworkshop\\venv\\lib\\site-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\agenticaiworkshop\\venv\\lib\\site-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\agenticaiworkshop\\venv\\lib\\site-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (2.12.3)\n",
      "Requirement already satisfied: sniffio in c:\\agenticaiworkshop\\venv\\lib\\site-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in c:\\agenticaiworkshop\\venv\\lib\\site-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\agenticaiworkshop\\venv\\lib\\site-packages (from anyio<5,>=3.5.0->groq<1.0.0,>=0.30.0->langchain-groq) (3.11)\n",
      "Requirement already satisfied: certifi in c:\\agenticaiworkshop\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->groq<1.0.0,>=0.30.0->langchain-groq) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\agenticaiworkshop\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->groq<1.0.0,>=0.30.0->langchain-groq) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\agenticaiworkshop\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1.0.0,>=0.30.0->langchain-groq) (0.16.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\agenticaiworkshop\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-groq) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\agenticaiworkshop\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-groq) (0.4.41)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\agenticaiworkshop\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-groq) (25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\agenticaiworkshop\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-groq) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\agenticaiworkshop\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-groq) (9.1.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\agenticaiworkshop\\venv\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain-groq) (3.0.0)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\agenticaiworkshop\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-groq) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\agenticaiworkshop\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-groq) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\agenticaiworkshop\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-groq) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\agenticaiworkshop\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-groq) (0.25.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\agenticaiworkshop\\venv\\lib\\site-packages (from pydantic<3,>=1.9.0->groq<1.0.0,>=0.30.0->langchain-groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in c:\\agenticaiworkshop\\venv\\lib\\site-packages (from pydantic<3,>=1.9.0->groq<1.0.0,>=0.30.0->langchain-groq) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\agenticaiworkshop\\venv\\lib\\site-packages (from pydantic<3,>=1.9.0->groq<1.0.0,>=0.30.0->langchain-groq) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\agenticaiworkshop\\venv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-groq) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\agenticaiworkshop\\venv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-groq) (2.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\nOkay, the user said \"Hello.\" I need to respond appropriately. Let me start by greeting them back in a friendly manner. Maybe add an emoji to keep it warm. Then, offer assistance. Keep it open-ended so they know I\\'m here to help with whatever they need. Make sure the response is concise but welcoming. Let me put that together.\\n</think>\\n\\nHi there! ðŸ˜Š How can I assist you today?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 89, 'prompt_tokens': 9, 'total_tokens': 98, 'completion_time': 0.172025853, 'prompt_time': 0.000289425, 'queue_time': 0.05779583, 'total_time': 0.172315278}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--eb2a6118-bb7d-4a16-9df8-58c8e271841e-0', usage_metadata={'input_tokens': 9, 'output_tokens': 89, 'total_tokens': 98})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pip install langchain-groq\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "llm_groq = ChatGroq(model=\"qwen/qwen3-32b\")\n",
    "llm_groq.invoke(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "785cb4a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-openai in c:\\agenticaiworkshop\\venv\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.2 in c:\\agenticaiworkshop\\venv\\lib\\site-packages (from langchain-openai) (1.0.3)\n",
      "Requirement already satisfied: openai<3.0.0,>=1.109.1 in c:\\agenticaiworkshop\\venv\\lib\\site-packages (from langchain-openai) (2.7.1)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in c:\\agenticaiworkshop\\venv\\lib\\site-packages (from langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\agenticaiworkshop\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\agenticaiworkshop\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai) (0.4.41)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\agenticaiworkshop\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai) (25.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\agenticaiworkshop\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai) (2.12.3)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\agenticaiworkshop\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\agenticaiworkshop\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\agenticaiworkshop\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai) (4.15.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\agenticaiworkshop\\venv\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.2->langchain-openai) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\agenticaiworkshop\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain-openai) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\agenticaiworkshop\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain-openai) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\agenticaiworkshop\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain-openai) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\agenticaiworkshop\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain-openai) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\agenticaiworkshop\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain-openai) (0.25.0)\n",
      "Requirement already satisfied: anyio in c:\\agenticaiworkshop\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain-openai) (4.11.0)\n",
      "Requirement already satisfied: certifi in c:\\agenticaiworkshop\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain-openai) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\agenticaiworkshop\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain-openai) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\agenticaiworkshop\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain-openai) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\agenticaiworkshop\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain-openai) (0.16.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\agenticaiworkshop\\venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\agenticaiworkshop\\venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.11.1)\n",
      "Requirement already satisfied: sniffio in c:\\agenticaiworkshop\\venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\agenticaiworkshop\\venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\agenticaiworkshop\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.2->langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in c:\\agenticaiworkshop\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.2->langchain-openai) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\agenticaiworkshop\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.2->langchain-openai) (0.4.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\agenticaiworkshop\\venv\\lib\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.11.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\agenticaiworkshop\\venv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain-openai) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\agenticaiworkshop\\venv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain-openai) (2.5.0)\n",
      "Requirement already satisfied: colorama in c:\\agenticaiworkshop\\venv\\lib\\site-packages (from tqdm>4->openai<3.0.0,>=1.109.1->langchain-openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRateLimitError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_openai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatOpenAI\n\u001b[32m      3\u001b[39m llm=ChatOpenAI(model=\u001b[33m\"\u001b[39m\u001b[33mgpt-4o\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHello\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\AgenticAIWorkshop\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:382\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    368\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    370\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    375\u001b[39m     **kwargs: Any,\n\u001b[32m    376\u001b[39m ) -> AIMessage:\n\u001b[32m    377\u001b[39m     config = ensure_config(config)\n\u001b[32m    378\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    379\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAIMessage\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    380\u001b[39m         cast(\n\u001b[32m    381\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m382\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m                \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    392\u001b[39m         ).message,\n\u001b[32m    393\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\AgenticAIWorkshop\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1091\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1082\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1083\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1084\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1088\u001b[39m     **kwargs: Any,\n\u001b[32m   1089\u001b[39m ) -> LLMResult:\n\u001b[32m   1090\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1091\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\AgenticAIWorkshop\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:906\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    903\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    904\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    905\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m906\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    907\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    908\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    909\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    910\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    911\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    912\u001b[39m         )\n\u001b[32m    913\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    914\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\AgenticAIWorkshop\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1195\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1193\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1194\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1195\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1196\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1197\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1198\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1199\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\AgenticAIWorkshop\\venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:1299\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1297\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m raw_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(raw_response, \u001b[33m\"\u001b[39m\u001b[33mhttp_response\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m   1298\u001b[39m         e.response = raw_response.http_response  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1299\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m   1300\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   1301\u001b[39m     \u001b[38;5;28mself\u001b[39m.include_response_headers\n\u001b[32m   1302\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m raw_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1303\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(raw_response, \u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1304\u001b[39m ):\n\u001b[32m   1305\u001b[39m     generation_info = {\u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response.headers)}\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\AgenticAIWorkshop\\venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:1294\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1287\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m _construct_lc_result_from_responses_api(\n\u001b[32m   1288\u001b[39m             response,\n\u001b[32m   1289\u001b[39m             schema=original_schema_obj,\n\u001b[32m   1290\u001b[39m             metadata=generation_info,\n\u001b[32m   1291\u001b[39m             output_version=\u001b[38;5;28mself\u001b[39m.output_version,\n\u001b[32m   1292\u001b[39m         )\n\u001b[32m   1293\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1294\u001b[39m         raw_response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwith_raw_response\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1295\u001b[39m         response = raw_response.parse()\n\u001b[32m   1296\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\AgenticAIWorkshop\\venv\\Lib\\site-packages\\openai\\_legacy_response.py:364\u001b[39m, in \u001b[36mto_raw_response_wrapper.<locals>.wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    360\u001b[39m extra_headers[RAW_RESPONSE_HEADER] = \u001b[33m\"\u001b[39m\u001b[33mtrue\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    362\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mextra_headers\u001b[39m\u001b[33m\"\u001b[39m] = extra_headers\n\u001b[32m--> \u001b[39m\u001b[32m364\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cast(LegacyAPIResponse[R], \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\AgenticAIWorkshop\\venv\\Lib\\site-packages\\openai\\_utils\\_utils.py:286\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    284\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\AgenticAIWorkshop\\venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:1156\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1110\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1111\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1112\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1153\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = not_given,\n\u001b[32m   1154\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m   1155\u001b[39m     validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m1156\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1157\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1158\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1159\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m   1160\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1161\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1162\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1163\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1164\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1165\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1166\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1167\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1168\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1169\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1170\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1171\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1172\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1173\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1174\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1175\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1176\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1177\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1178\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1179\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1180\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1181\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1184\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1185\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1186\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1187\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1188\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1189\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1190\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1191\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1192\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mverbosity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1194\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1195\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m   1196\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m   1197\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1198\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1199\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1200\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m   1201\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1202\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1203\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1204\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1205\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\AgenticAIWorkshop\\venv\\Lib\\site-packages\\openai\\_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\AgenticAIWorkshop\\venv\\Lib\\site-packages\\openai\\_base_client.py:1047\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1044\u001b[39m             err.response.read()\n\u001b[32m   1046\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1047\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mRateLimitError\u001b[39m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "%pip install langchain-openai\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm=ChatOpenAI(model=\"gpt-4o\")\n",
    "llm.invoke(\"Hello\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d60372",
   "metadata": {},
   "source": [
    "## We Will start with Creating Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4b200ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def superbot(state:State):\n",
    "    return {\"messages\":[llm_groq.invoke(state['messages'])]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0924059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph=StateGraph(State)\n",
    "\n",
    "##node\n",
    "graph.add_node(\"Superbot\",superbot)\n",
    "\n",
    "## Edges\n",
    "graph.add_edge(START,\"Superbot\")\n",
    "graph.add_edge(\"Superbot\",END)\n",
    "\n",
    "graph_builder=graph.compile()\n",
    "\n",
    "## Display\n",
    "from IPython.display import  Image,display\n",
    "display(Image(graph_builder.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6c3503d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Hi,My name is Himanshu  and i like foootball', additional_kwargs={}, response_metadata={}, id='344873ad-fc55-4731-902c-f341dbe5aef8'),\n",
       "  AIMessage(content='<think>\\nOkay, the user mentioned he likes football. Let me start by acknowledging that. I should ask which team he supports to keep the conversation going. Maybe also ask how he got into football. I need to make sure the response is friendly and open-ended. Oh, and correct the typo in \"foootball\" to \"football\" politely. Let me check if there\\'s anything else. Maybe mention something about the sport to show interest. Yeah, something like the excitement of matches or famous players. Keep it natural and not too formal. Alright, let me put that together.\\n</think>\\n\\nHey Himanshu! Nice to meet you! ðŸŽ‰ You mentioned you like footballâ€”do you follow any particular team or player? Iâ€™d love to hear what got you into the sport! (And no worries about the typoâ€”I know exactly what you meant with \"foootball\" ðŸ˜‰) Football\\'s such an amazing game, isnâ€™t it? The energy during matches is always electric!', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 201, 'prompt_tokens': 23, 'total_tokens': 224, 'completion_time': 0.549634861, 'prompt_time': 0.000955062, 'queue_time': 0.421489086, 'total_time': 0.550589923}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_fbaaebd3ce', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--cb2330b3-26f5-457d-a903-cedb47cac95f-0', usage_metadata={'input_tokens': 23, 'output_tokens': 201, 'total_tokens': 224})]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder.invoke({\"messages\":\"Hi,My name is Himanshu  and i like foootball\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba1fe5f",
   "metadata": {},
   "source": [
    "## Streaming The response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3bc857a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Superbot': {'messages': [AIMessage(content=\"<think>\\nOkay, the user introduced himself as Himanshu. I should respond with a friendly greeting in return. I'll ask how I can assist him today. Keep it simple and welcoming.\\n</think>\\n\\nHello Himanshu! Nice to meet you. How can I assist you today? ðŸ˜Š\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 61, 'prompt_tokens': 15, 'total_tokens': 76, 'completion_time': 0.143395641, 'prompt_time': 0.00063793, 'queue_time': 0.05316622, 'total_time': 0.144033571}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--53080192-c96c-4172-be32-d79cc2dc0d92-0', usage_metadata={'input_tokens': 15, 'output_tokens': 61, 'total_tokens': 76})]}}\n"
     ]
    }
   ],
   "source": [
    "for event in graph_builder.stream({\"messages\":\"Hello my name is Himanshu\"}):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2de26ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
