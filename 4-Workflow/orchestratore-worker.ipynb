{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5145ef8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "llm=ChatGroq(model=\"qwen/qwen3-32b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1649cf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated,List\n",
    "import operator\n",
    "from typing_extensions import Literal,TypedDict\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.messages import HumanMessage,SystemMessage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d461e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema for structured output to use in planning \n",
    "class Section(BaseModel):\n",
    "    name:str=Field(description=\"Name for this section of the report\")\n",
    "    description:str=Field(description=\"Brief overview of the main topics and concepts of the section\")\n",
    "\n",
    "class Sections(BaseModel):\n",
    "    sections:List[Section]=Field(description=\"Sections of the  report\")\n",
    "\n",
    "# Augment the LLM with schema for sructured output\n",
    "planner = llm.with_structured_output(Sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff6ce7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Himanshu\\AppData\\Local\\Temp\\ipykernel_17028\\1296749769.py:1: LangGraphDeprecatedSinceV10: Importing Send from langgraph.constants is deprecated. Please use 'from langgraph.types import Send' instead. Deprecated in LangGraph V1.0 to be removed in V2.0.\n",
      "  from langgraph.constants import Send\n"
     ]
    }
   ],
   "source": [
    "from langgraph.constants import Send\n",
    "\n",
    "# Graph state\n",
    "class State(TypedDict):\n",
    "    topic:str \n",
    "    sections: list[Section]\n",
    "    completed_sections: Annotated[list ,operator.add] # All worker write to this key in parallel\n",
    "    final_report:str\n",
    "\n",
    "class WorkerState(TypedDict):\n",
    "    section:Section\n",
    "    completed_sections: Annotated[list,operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d3a31ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nodes \n",
    "def orchestrator(state:State):\n",
    "    \"\"\"orchestrator that generates a plan for the report\"\"\"\n",
    "    \n",
    "    # Generate queries\n",
    "    report_sections = planner.invoke(\n",
    "        [\n",
    "            SystemMessage(content = \"Generate a plan for the report\"),\n",
    "            HumanMessage(content=f\"Here is the report topic: {state['topic']}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    print(\"Report Sections :\",report_sections)\n",
    "    return {\"sections\": report_sections.sections}\n",
    "\n",
    "def llm_call(state: WorkerState):\n",
    "    \"\"\"Worker writes a section of the report\"\"\"\n",
    "\n",
    "    # Generate section\n",
    "    section = llm.invoke(\n",
    "        [\n",
    "            SystemMessage(content=\"write a report section following the provided name and description. Include no premable for each section\"),\n",
    "\n",
    "            HumanMessage(content=f\"Here is the section name: {state['section'].name} and description: {state['section'].description}\"),\n",
    "\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Write the updated section to completed sections\n",
    "    return {\"completed_sections\": [section.content]}\n",
    "\n",
    "# Conditional edge function to create llm_call workers that each write a section of the report\n",
    "def assign_workers(state:State):\n",
    "    \"\"\"Assign a worker to each section in the plan \"\"\"\n",
    "\n",
    "    # kick off section writing in parallel via Send() API\n",
    "    return [Send(\"llm_call\",{\"section\":s}) for s in state[\"section\"]]\n",
    "\n",
    "def synthesizer(state:State):\n",
    "    \"\"\"Synthesize full report from sections\"\"\"\n",
    "    # List of completed sections\n",
    "    completed_sections = state[\"completed_sections\"]\n",
    "\n",
    "    # Format completed section to str to use as context for final sections\n",
    "    completed_report_sections= \"\\n\\n---\\n\\n\".join(completed_sections)\n",
    "\n",
    "    return {\"final_report\":completed_report_sections}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "714058c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "At 'orchestrator' node, 'assign_workers' branch found unknown target '<function llm_call at 0x00000272D255BBA0>'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     16\u001b[39m orchestrator_worker_builder.add_edge(\u001b[33m\"\u001b[39m\u001b[33msynthesizer\u001b[39m\u001b[33m\"\u001b[39m,END)\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Compile the workflow\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m orchestrator_worker=\u001b[43morchestrator_worker_builder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# show the workflow\u001b[39;00m\n\u001b[32m     22\u001b[39m display(Image(orchestrator_worker.get_graph().draw_mermaid_png()))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\AgenticAIWorkshop\\venv\\Lib\\site-packages\\langgraph\\graph\\state.py:844\u001b[39m, in \u001b[36mStateGraph.compile\u001b[39m\u001b[34m(self, checkpointer, cache, store, interrupt_before, interrupt_after, debug, name)\u001b[39m\n\u001b[32m    841\u001b[39m interrupt_after = interrupt_after \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[32m    843\u001b[39m \u001b[38;5;66;03m# validate the graph\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m844\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    845\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    846\u001b[39m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m \u001b[49m\u001b[43m!=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m*\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43minterrupt_after\u001b[49m\n\u001b[32m    847\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m \u001b[49m\u001b[43m!=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m*\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m    848\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    849\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    850\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    852\u001b[39m \u001b[38;5;66;03m# prepare output channels\u001b[39;00m\n\u001b[32m    853\u001b[39m output_channels = (\n\u001b[32m    854\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m__root__\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    855\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.schemas[\u001b[38;5;28mself\u001b[39m.output_schema]) == \u001b[32m1\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    861\u001b[39m     ]\n\u001b[32m    862\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\AgenticAIWorkshop\\venv\\Lib\\site-packages\\langgraph\\graph\\state.py:785\u001b[39m, in \u001b[36mStateGraph.validate\u001b[39m\u001b[34m(self, interrupt)\u001b[39m\n\u001b[32m    783\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m end \u001b[38;5;129;01min\u001b[39;00m branch.ends.values():\n\u001b[32m    784\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.nodes \u001b[38;5;129;01mand\u001b[39;00m end != END:\n\u001b[32m--> \u001b[39m\u001b[32m785\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    786\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAt \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m node, \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcond\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m branch found unknown target \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    787\u001b[39m             )\n\u001b[32m    788\u001b[39m         all_targets.add(end)\n\u001b[32m    789\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mValueError\u001b[39m: At 'orchestrator' node, 'assign_workers' branch found unknown target '<function llm_call at 0x00000272D255BBA0>'"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, START,END\n",
    "orchestrator_worker_builder = StateGraph(State)\n",
    "from IPython.display import Image, display\n",
    "\n",
    "## ADD the nodes\n",
    "orchestrator_worker_builder.add_node(\"orchestrator\",orchestrator)\n",
    "orchestrator_worker_builder.add_node(\"llm_call\",llm_call)\n",
    "orchestrator_worker_builder.add_node(\"synthesizer\",synthesizer)\n",
    "\n",
    "# add edges to connect nodes\n",
    "orchestrator_worker_builder.add_edge(START,\"orchestrator\")\n",
    "orchestrator_worker_builder.add_conditional_edges(\n",
    "    \"orchestrator\",assign_workers,[llm_call]\n",
    ")\n",
    "orchestrator_worker_builder.add_edge(\"llm_call\",\"synthesizer\")\n",
    "orchestrator_worker_builder.add_edge(\"synthesizer\",END)\n",
    "\n",
    "# Compile the workflow\n",
    "orchestrator_worker=orchestrator_worker_builder.compile()\n",
    "\n",
    "# show the workflow\n",
    "display(Image(orchestrator_worker.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddae4b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
